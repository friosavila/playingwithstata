<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="format-detection" content="telephone=no">
<title>DGP for CQR</title>
<style>
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
html { -webkit-text-size-adjust: 100%; }
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 14px; line-height: 1.428;
  margin: 0 auto; padding: 0 15px;
}
h1, h2, h3, h4, h5, h6 { margin: 20px 0 10px; }
h1 { font-size: 28px; } h2 { font-size: 24px; }
h3 { font-size: 18px; } h4 { font-size: 16px; }
h5 { font-size: 14px; } h6 { font-size: 12px; }
a { color: #337AB7; text-decoration: none; }
a:hover { text-decoration: underline; }
img { max-width: 100%; height: auto; }
ul, ol { padding-left: 30px; }
pre, code, samp {
  font-size: 13px;
  font-family: Courier, monospace;
}
code, samp {
  background-color: #F5F5F5;
  border-radius: 3px; padding: 3px;
}
pre code, pre samp {
  white-space: pre; background: transparent;
  border: none; padding: 0;
}
pre {
  line-height: 1.33; background-color: #F5F5F5;
  border: 1px solid #CCCCCC; border-radius: 3px;
  padding: 8px; overflow: auto;
}
</style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script><style>
.stlog { color: #000000; background-color: #F0F3F9; }
.stres { color: #324F58; }
.stinp { font-weight: bold; color: #000000; }
.stcmd .stcmt { font-style: italic; opacity: 0.5; }
.stoom, .stcnp { font-style: italic; }
@media screen { .stcnp { display: none; }}
</style>
</head>
<body>
<h1>Conditional Quantile Regressions: A simulation approach</h1>
First apologies. I have been working on the third part of my Qreg interpretation "blog", but has been taking longer than expected, as I'm struggling to find a balance between length, technical details, and what is more important (and motivated me to write that), the interpretation. But, I have not forgotten about that. It is coming.
<br><br>
Now something I realized while writing about Conditional quantile regression, is that we (or at least when I learned this topic), fail to understand what conditional quantile regressions do because it is hard to think about how data looks like in terms of the Data generating process (DGP).
<br><br>
So, to help address this problem, I will provide you here two ways of thinking about what Conditional quantile regressions do, from the perspective of the underlying DGP. So let's start.

<h2>Conditional Quantile regressions: A tale of unobserved heterogeneity</h2>
As the title suggests, one of the ways of thinking about DGP and what conditional quantile regressions do is to think in terms of unobserved heterogeneity. Something, that we cannot control for that is interacting with the effect of observed variables, which can the effect of those variables vary across individuals. 
<br><br> 
On this regard, while unobserved factors that cause the heterogeneity cannot be observed, CQR tries to identify this heterogeneity by imposing some identification assumptions that relate to conditional distributions, but not necessarily individual experiences. 
<br><br>
Namely, consider the conditional distribution of Y that can be written as $F_{Y|X}$. Given this function, it is also possible to identify the conditional quantile as $F^{-1}_{y|x}(\tau)=Q_{y|X}(\tau)$. 
<br><br>
The first identification assumption for conditional quantiles (whichever method you choose to apply) is that:

$$ Q_{y|X}(\tau_1) \leq Q_{y|X}(\tau_2) \iff \tau_1 \leq \tau_2 $$

In other words, conditional quantiles have to be non decreasing in $\tau$. This is an obvious condition, but it does impose important constrains on the on how estimators attempt to identify conditional quantiles. 
<br><br>
Specifically, Assume that conditional quantiles can be estimated using some functional form as follows:

$$ Q_{y|X}(\tau) = g(X,\tau) $$

Under very specific circumstances, if we know an observations $x_i$ and $\tau_i$ (which is a stand-in for the unobserved component), we will have the following:

$$ y_i = g(X_i,\tau_i) = Q_{y|X=x_i}(\tau_i) $$

This means that we could use the same function $g()$ to determine a conditional quantile and the outcome for any particular observation. 
And if this is true, that means the "rank invariance" assumption holds. And we could analyze how $y$ when either $x$ changes if $\tau_i$ remains the same, or $\tau$ changes assuming $x$ remains the same. 

<h3>So where is the heterogeneity?</h3>
As I already mention, all conditional quantile regression methods attempt to identify the function $g(X,\tau)$. To do so, most impose some functional form on $g()$ that would help to identify relationships across all observations who have the same "ranking" $\tau$ but different $X$. The opposite, identifying all quantiles $\tau$ across observations with the same $X$ is also possible, but require may work, depending on the dimension of $X$.
<br><br>
The most common approach, which I'll use for the data simulation, is to assume that, for a fixed $\tau$, the function $g()$ is linear in $X$:
$$ Q_{y|X}(\tau) = g(X,\tau) = X*\beta(\tau)$$

In this setup, the unobserved heterogeneity comes from $\beta(\tau)$ , because we never really know what quantile $\tau$ a person belongs to, the same way that we never observe the true error in a standard LR model. Additionally, quantile regression algorithms will find $\betas(\tau)$ that may generate "reasonable" quantiles, but you may also observe quantile crossings where predicted 90th quantile may have a value below than 10th quantile, for combinations of characteristics that are rare or unobserved in the actual data.

<h2>DGP for conditional quantile regressions</h2>

There are two DGP that have been considered and used for explaining what do CQR does. The first approach is the one I have previously described:
$$y_i=x_i*\beta(\tau_i) \quad \tau_i \sim uniform(0,1) $$
This specification basically assumes a kind of random coefficients models that depend on $\tau$, which follows a uniform distribution (0,1). To simplify things, one usually assumes $\beta(\tau_i)$ to be some linear or nonlinear function of $\tau$.
<br><br>
The second DGP that has been used, and is often more intuitive, is to assume a model with known heteroskedasticity:
$$y_i=g(x)+v_i *h(x) \quad v_i \sim iid \quad or $$
$$y_i=x_i*\beta+v_i *(x_i*\gamma) \quad v_i \sim iid $$
This second approach, however, is a special case of the first one, if we assume that $v_i = F^-1_v(\tau_i)$:
$$y_i=x_i*(\beta+v_i *\gamma)  =  x_i*(\beta+F_v^-1(\tau) *\gamma) = x_i*\beta(\tau_i)$$
Now, if we want to use this DGP process to simulate data, and verify that any particular algorithm (like -qreg-) replicates the "theoretical" quantile beta coefficients $\beta(\tau)$, we need to remember that the first assumption I started with holds:
$$ Q_{y|X}(\tau_1) \leq Q_{y|X}(\tau_2) \iff \tau_1 \leq \tau_2$$
As far as I know, in the case of the random coefficients approach, no general conditions exist to garrantie monotonically increasing conditional quantiles. However, for the heteroskedastic error approach, one simply needs $h(x)$ to be strictly possitive.
<br><br>
Alright, so with this in mind, some coding. 
<pre id="stlog-1" class="stlog"><samp><span class="stinp">. <span class="stcmt">** General set up</span></span>
<span class="stinp">. <span class="stcmt">** Generating 1000 obs</span></span>
<span class="stinp">. clear</span>

<span class="stinp">. set obs 1000</span>
number of observations (_N) was 0, now 1,000

<span class="stinp">. set seed 1</span>

<span class="stinp">. <span class="stcmt">** and generating TAU</span></span>
<span class="stinp">. gen tau = runiform()</span>

<span class="stinp">. gen tau100=tau*100</span>

<span class="stinp">. <span class="stcmt">** I create X1 and X2 to be strictly possitive correlated variables. </span></span>
<span class="stinp">. gen corr_factor=rnormal()</span>

<span class="stinp">. gen x1=ceil( 3*normal((0.4*rnormal()+0.6*corr_factor)) *10)/10</span>

<span class="stinp">. gen x2=ceil( abs( 0.4*rnormal()+0.6*corr_factor) *10)/10</span>

<span class="stinp">. <span class="stcmt">** For Option 1, I will take the random coefficients aproach.</span></span>
<span class="stinp">. <span class="stcmt">** Where the betas are functions of tau</span></span>
<span class="stinp">. gen b0 = tau*2-tau^2</span>

<span class="stinp">. gen b1 = 2*tau^2</span>

<span class="stinp">. gen b2 = normal((tau-.5)*7)</span>

<span class="stinp">. <span class="stcmt">** The outcome is then the randome coefficients times the characteristics</span></span>
<span class="stinp">. gen y_1 = b0 + b1 *x1 +b2*x2</span>

<span class="stinp">. reg y_1 x1 x2</span>

      Source |       SS           df       MS      Number of obs   =<span class="stres">     1,000</span>
-------------+----------------------------------   F(2, 997)       = <span class="stres">    81.76</span>
       Model | <span class="stres"> 344.698238         2  172.349119   </span>Prob &gt; F        =<span class="stres">    0.0000</span>
    Residual | <span class="stres"> 2101.67094       997  2.10799492   </span>R-squared       =<span class="stres">    0.1409</span>
-------------+----------------------------------   Adj R-squared   =<span class="stres">    0.1392</span>
       Total | <span class="stres"> 2446.36918       999    2.448818   </span>Root MSE        =   <span class="stres"> 1.4519</span>

------------------------------------------------------------------------------
         y_1 |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |<span class="stres">   .7799979   .0646359    12.07   0.000     .6531599    .9068359</span>
          x2 |<span class="stres">   .4916657   .1062022     4.63   0.000     .2832603    .7000712</span>
       _cons |<span class="stres">   .5588526    .130174     4.29   0.000     .3034061    .8142992</span>
------------------------------------------------------------------------------

<span class="stinp">. <span class="stcmt">** for Option 2, I will use a model with with heteroskedasticity</span></span>
<span class="stinp">. <span class="stcmt">** first the iid error (with mean 0) (here normal)</span></span>
<span class="stinp">. gen v = invnormal(tau)</span>

<span class="stinp">. </span>
<span class="stinp">. <span class="stcmt">** and the model with heteroskedasticity could be:</span></span>
<span class="stinp">. <span class="stcmt">* y_2 = 0.5 + 0.5 * x1 + 0.5 * x2 + v*(2 - 0.2* x1 + x2)</span></span>
<span class="stinp">. <span class="stcmt">** THis implies the following Betas:</span></span>
<span class="stinp">. gen g0 = 0.5 + 2* invnormal(tau)</span>

<span class="stinp">. gen g1 = 0.5 -.2* invnormal(tau)</span>

<span class="stinp">. gen g2 = 0.5 + 1* invnormal(tau)</span>

<span class="stinp">. <span class="stcmt">** so the data can be created like this:</span></span>
<span class="stinp">. <span class="stcmt">* gen y_21= 0.5 + 0.5 * x1 + 0.5 * x2 + v*(2 - 0.2* x1 + x2)</span></span>
<span class="stinp">. <span class="stcmt">** or like this:</span></span>
<span class="stinp">. gen y_2 = g0 + g1*x1+g2*x2</span>
</samp></pre>
So here you have two different examples of how to generate quantile regressions. 
Now to see how well these coefficients can be identified using -qreg-, we can estimate series of CQR, and compared the coefficients with the True coefficients.
Here an example:
<pre id="stlog-2" class="stlog"><samp><span class="stinp">. <span class="stcmt">** Model with random coefficients</span></span>
<span class="stinp">. qui:qreg y_1 x1 x2, nolog</span>

<span class="stinp">. qregplot x1 x2, cons  raopt( color(gs4%50)) q(5(5)95)</span>

<span class="stinp">. addplot 1:line b1 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. addplot 2:line b2 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. addplot 3:line b0 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. graph export qdgp1.png, replace</span>
(file qdgp1.png written in PNG format)
</samp></pre>
<img src="qdgp1.png" class="center">
<pre id="stlog-3" class="stlog"><samp><span class="stinp">. <span class="stcmt">** Model with Heteroskedastic errors </span></span>
<span class="stinp">. qui:qreg y_2 x1 x2, nolog</span>

<span class="stinp">. qregplot x1 x2, cons   raopt( color(gs4%50)) q(5(5)95)</span>

<span class="stinp">. addplot 1:line g1 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. addplot 2:line g2 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. addplot 3:line g0 tau100 if inrange(tau100,4,96), sort lwidth(1)</span>

<span class="stinp">. graph export qdgp2.png, replace</span>
(file qdgp2.png written in PNG format)
</samp></pre>
<img src="qdgp1.png" class="center">
<br>
Of course, a simple 1 shot exercise is not enough to judge how qreg replicates DGP coefficients (or if the DGP coefficients as created correspond to the qreg coefficients). So to do this, I can just prepare a small Montecarlo simulation exercise. First for the random coefficients
<pre id="stlog-4" class="stlog"><samp><span class="stinp">. <span class="stcmt">** Create data:</span></span>
<span class="stinp">. clear</span>

<span class="stinp">. set obs 1000</span>
number of observations (_N) was 0, now 1,000

<span class="stinp">. set seed 1</span>

<span class="stinp">. gen tau = runiform()</span>

<span class="stinp">. gen corr_factor=rnormal()</span>

<span class="stinp">. gen x1=ceil( 3*normal((0.4*rnormal()+0.6*corr_factor)) *10)/10</span>

<span class="stinp">. gen x2=ceil( abs( 0.4*rnormal()+0.6*corr_factor) *10)/10</span>

<span class="stinp">. gen b0=.</span>
(1,000 missing values generated)

<span class="stinp">. gen b1=.</span>
(1,000 missing values generated)

<span class="stinp">. gen b2=.</span>
(1,000 missing values generated)

<span class="stinp">. gen y_1=.</span>
(1,000 missing values generated)

<span class="stinp">. <span class="stcmt">** and simulate</span></span>
<span class="stinp">. program sim_qreg1</span>
  1<span class="stinp">.         replace tau = runiform()</span>
  2<span class="stinp">.         replace b0 = tau*2-tau^2</span>
  3<span class="stinp">.         replace b1 = 2*tau^2</span>
  4<span class="stinp">.         replace b2 = normal((tau-.5)*7)</span>
  5<span class="stinp">.         <span class="stcmt">** The outcome is then the randome coefficients times the characteristics</span></span>
<span class="stinp">.         replace y_1 = b0 + b1 *x1 +b2*x2</span>
  6<span class="stinp">.         qreg y_1 x1 x2, q(10)</span>
  7<span class="stinp">.         matrix b1=e(b)-[2*0.1^2, normal((0.1-.5)*7), 0.1*2-0.1^2]</span>
  8<span class="stinp">.         qreg y_1 x1 x2, q(50)</span>
  9<span class="stinp">.         matrix b2=e(b)-[2*0.5^2, normal((0.5-.5)*7), 0.5*2-0.5^2]</span>
 10<span class="stinp">.         qreg y_1 x1 x2, q(90)</span>
 11<span class="stinp">.         matrix b3=e(b)-[2*0.9^2, normal((0.9-.5)*7), 0.9*2-0.9^2]</span>
 12<span class="stinp">.         matrix coleq b1 = q10</span>
 13<span class="stinp">.         matrix coleq b2 = q50</span>
 14<span class="stinp">.         matrix coleq b3 = q90</span>
 15<span class="stinp">.         matrix colname b1 =b1 b2 b0</span>
 16<span class="stinp">.         matrix colname b2 =b1 b2 b0</span>
 17<span class="stinp">.         matrix colname b3 =b1 b2 b0</span>
 18<span class="stinp">.         matrix b =b1,b2,b3</span>
 19<span class="stinp">.         ereturn post b</span>
 20<span class="stinp">. end</span>

<span class="stinp">. set seed 10</span>

<span class="stinp">. simulate, reps(500):sim_qreg1</span>

      command:  sim_qreg1

Simulations (<span class="stres">500</span>)
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 
..................................................    50
..................................................   100
..................................................   150
..................................................   200
..................................................   250
..................................................   300
..................................................   350
..................................................   400
..................................................   450
..................................................   500

<span class="stinp">. sum</span>

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
    q10_b_b1 |<span class="stres">        500    .0020959    .0314996  -.0944763   .0842208</span>
    q10_b_b2 |<span class="stres">        500    .0026978    .0550713    -.15062   .1787767</span>
    q10_b_b0 |<span class="stres">        500   -.0019955     .062238   -.193784   .2200285</span>
    q50_b_b1 |<span class="stres">        500    .0041795    .1257314  -.3433639   .4478617</span>
    q50_b_b2 |<span class="stres">        500   -.0049844    .2248479  -.6915638   .5949767</span>
-------------+---------------------------------------------------------
    q50_b_b0 |<span class="stres">        500   -.0094913    .2190925  -.6788032   .7094005</span>
    q90_b_b1 |<span class="stres">        500    .0016747    .0706185  -.2597727    .200851</span>
    q90_b_b2 |<span class="stres">        500   -.0047536    .0953134  -.3292854   .2505159</span>
    q90_b_b0 |<span class="stres">        500   -.0046887    .1150711   -.370228   .4183795</span>
</samp></pre>
If everything works the way it's supposed to, the means should be close to zero. And that is what we see here. (although you may argue, they are small but not quite zero). Remember, one should normally use 10000 simulations, not 500 as I did here.
<br><br>
For completeness, we can do this again for the heteroscedastic model:
<pre id="stlog-5" class="stlog"><samp><span class="stinp">. clear</span>

<span class="stinp">. set obs 1000</span>
number of observations (_N) was 0, now 1,000

<span class="stinp">. set seed 1</span>

<span class="stinp">. gen tau = runiform()</span>

<span class="stinp">. gen corr_factor=rnormal()</span>

<span class="stinp">. gen x1=ceil( 3*normal((0.4*rnormal()+0.6*corr_factor)) *10)/10</span>

<span class="stinp">. gen x2=ceil( abs( 0.4*rnormal()+0.6*corr_factor) *10)/10</span>

<span class="stinp">. gen g0=.</span>
(1,000 missing values generated)

<span class="stinp">. gen g1=.</span>
(1,000 missing values generated)

<span class="stinp">. gen g2=.</span>
(1,000 missing values generated)

<span class="stinp">. gen y_2=.</span>
(1,000 missing values generated)

<span class="stinp">. <span class="stcmt">** and simulate</span></span>
<span class="stinp">. program sim_qreg2</span>
  1<span class="stinp">.         replace tau = runiform()</span>
  2<span class="stinp">.         replace g0 = 0.5 + 2* invnormal(tau)</span>
  3<span class="stinp">.         replace g1 = 0.5 -.2* invnormal(tau)</span>
  4<span class="stinp">.         replace g2 = 0.5 + 1* invnormal(tau)</span>
  5<span class="stinp">.         <span class="stcmt">** The outcome is then the randome coefficients times the characteristics</span></span>
<span class="stinp">.         replace y_2 = g0 + g1 *x1 +g2*x2</span>
  6<span class="stinp">.         qreg y_2 x1 x2, q(10)</span>
  7<span class="stinp">.         matrix b1=e(b)-[ 0.5 -.2* invnormal(.1) , 0.5 + 1* invnormal(.1), 0.5 + 2* invnormal(.1)]</span>
  8<span class="stinp">.         qreg y_2 x1 x2, q(50)</span>
  9<span class="stinp">.         matrix b2=e(b)-[ 0.5 -.2* invnormal(.5) , 0.5 + 1* invnormal(.5), 0.5 + 2* invnormal(.5)]</span>
 10<span class="stinp">.         qreg y_2 x1 x2, q(90)</span>
 11<span class="stinp">.         matrix b3=e(b)-[ 0.5 -.2* invnormal(.9) , 0.5 + 1* invnormal(.9), 0.5 + 2* invnormal(.9)]</span>
 12<span class="stinp">.         matrix coleq b1 = q10</span>
 13<span class="stinp">.         matrix coleq b2 = q50</span>
 14<span class="stinp">.         matrix coleq b3 = q90</span>
 15<span class="stinp">.         matrix colname b1 =b1 b2 b0</span>
 16<span class="stinp">.         matrix colname b2 =b1 b2 b0</span>
 17<span class="stinp">.         matrix colname b3 =b1 b2 b0</span>
 18<span class="stinp">.         matrix b =b1,b2,b3</span>
 19<span class="stinp">.         ereturn post b</span>
 20<span class="stinp">. end</span>

<span class="stinp">. set seed 10</span>

<span class="stinp">. simulate, reps(500):sim_qreg2</span>

      command:  sim_qreg2

Simulations (<span class="stres">500</span>)
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 
..................................................    50
..................................................   100
..................................................   150
..................................................   200
..................................................   250
..................................................   300
..................................................   350
..................................................   400
..................................................   450
..................................................   500

<span class="stinp">. sum </span>

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
    q10_b_b1 |<span class="stres">        500    .0075737    .1731368  -.4866515    .446491</span>
    q10_b_b2 |<span class="stres">        500   -.0007046    .3432789  -1.213517   1.093244</span>
    q10_b_b0 |<span class="stres">        500   -.0103895    .3511256  -1.052383   1.110389</span>
    q50_b_b1 |<span class="stres">        500    .0064221    .1327437  -.3747905   .4203672</span>
    q50_b_b2 |<span class="stres">        500   -.0055896    .2414599  -.8344932   .7398532</span>
-------------+---------------------------------------------------------
    q50_b_b0 |<span class="stres">        500    -.013601    .2657093  -.9403573   .6856188</span>
    q90_b_b1 |<span class="stres">        500    .0070179    .1801566  -.5743021   .5326937</span>
    q90_b_b2 |<span class="stres">        500   -.0110105    .3558143  -1.035386   .9824824</span>
    q90_b_b0 |<span class="stres">        500   -.0073229    .3626464  -1.048338   1.119514</span>
</samp></pre>
And again, we can see that the mean of coefficients is very close to zero, which suggest that the theoretical coefficients do match the coefficients identified by -qreg-.
<br> <br>
One thing that I have found useful for analyzing CQR, in terms of the DGP, is to see what happens when the rank invariance assumption does not hold. This is a kind of counter-example, that may help understand why CQR cannot always be interpreted as individual effects, but effects across distributions.
<br><br>
For this example, I will concentrate on a model with a single explanatory variable, and use the random coefficients approach:
<pre id="stlog-6" class="stlog"><samp><span class="stinp">. <span class="stcmt">*** create 1000 obs</span></span>
<span class="stinp">. clear</span>

<span class="stinp">. set obs 1000</span>
number of observations (_N) was 0, now 1,000

<span class="stinp">. set seed 10</span>

<span class="stinp">. <span class="stcmt">*** create x to be positive (similar to above)</span></span>
<span class="stinp">. gen x = 3*runiform()</span>

<span class="stinp">. <span class="stcmt">*** create Tau</span></span>
<span class="stinp">. gen tau  = runiform()</span>

<span class="stinp">. <span class="stcmt">*** and create two random coefficients</span></span>
<span class="stinp">. gen b0 = tau-.5</span>

<span class="stinp">. gen b1 = .5-tau</span>

<span class="stinp">. <span class="stcmt">*** create the outcome</span></span>
<span class="stinp">. gen y = b0 + b1* x</span>
</samp></pre>
This isn't obvious, but for this model, the rank invariance assumption does not hold. This is easy to see, if we plot the data above, color coding for different levels of $\tau$.
<pre id="stlog-7" class="stlog"><samp><span class="stinp">. two scatter y x, color(%20) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.1)&lt;.05 || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.5)&lt;.05 || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.9)&lt;.05, <span class="stcmt">///</span>
&gt;         legend(order(2 "Tau ~ 0.1" 3 "Tau ~ 0.5" 4 "Tau ~ 0.9") cols(3))</span>

<span class="stinp">. graph export qdgp3.png, replace</span>
(file qdgp3.png written in PNG format)
</samp></pre>
<img src="qdgp3.png" class="center">	
<br>
So what we see here is that the rank invariance assumption holds, but only for $X<1$. When $X>1$, everything flips. Observations with a smaller $\tau$, have a larger $y$, and vice-versa. This implies that this DGP does create heterogeneity, but the $\beta 's$ cannot be identified by -qreg-.
<br> <br> 
A simple way to see this is to estimate CQR, and plot the predicted values for those models:
<pre id="stlog-8" class="stlog"><samp><span class="stinp">. qui:qreg y  x  , q(10)</span>

<span class="stinp">. predict q10</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. qui:qreg y  x  , q(50)</span>

<span class="stinp">. predict q50</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. qui:qreg y  x  , q(90)</span>

<span class="stinp">. predict q90</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. two scatter y x, color(%20) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.1)&lt;.05, color(navy) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.5)&lt;.05, color(maroon) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.9)&lt;.05, color(forest_green) || <span class="stcmt">///</span>
&gt;         line q10 q50 q90 x, sort lw(1 1 1) color( navy maroon forest_green) <span class="stcmt">///</span>
&gt;         legend(order(2 "Tau ~ 0.1" 3 "Tau ~ 0.5" 4 "Tau ~ 0.9" <span class="stcmt">///</span>
&gt;         5 "q10hat" 6 "q50hat" 7 "q90hat" ) cols(3))</span>

<span class="stinp">. graph export qdgp4.png, replace</span>
(file qdgp4.png written in PNG format)
</samp></pre>
<img src="qdgp4.png" class="center">	
<br>
As you can see, qreg (and any other program) estimates coefficients so that higher predicted quantiles are always larger than lower quantiles (at least within the observed range of $x$). 
<br><br>
In this case, the rank invariance assumption does not hold, and the model specification is incorrect. It would be better to describe effects as simply comparing conditional distributions. Also, a better approximation could be using a quadratic term or a simple spline:
<pre id="stlog-9" class="stlog"><samp><span class="stinp">. <span class="stcmt">*ssc install f_able</span></span>
<span class="stinp">. f_spline d=x, k(1)</span>

<span class="stinp">. qui:qreg y  x d2 , q(10)</span>

<span class="stinp">. predict q10x</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. qui:qreg y  x d2 , q(50)</span>

<span class="stinp">. predict q50x</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. qui:qreg y  x d2 , q(90)</span>

<span class="stinp">. predict q90x</span>
(option <span class="stres">xb</span> assumed; fitted values)

<span class="stinp">. </span>
<span class="stinp">. two scatter y x, color(%20) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.1)&lt;.05, color(navy) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.5)&lt;.05, color(maroon) || <span class="stcmt">///</span>
&gt;         scatter y x if abs(tau-.9)&lt;.05, color(forest_green) || <span class="stcmt">///</span>
&gt;         line q10x q50x q90x x, sort lw(1 1 1) color( navy maroon forest_green) <span class="stcmt">///</span>
&gt;         legend(order(2 "Tau ~ 0.1" 3 "Tau ~ 0.5" 4 "Tau ~ 0.9" <span class="stcmt">///</span>
&gt;         5 "q10hat" 6 "q50hat" 7 "q90hat" ) cols(3))</span>

<span class="stinp">. graph export qdgp5.png, replace</span>
(file qdgp5.png written in PNG format)
</samp></pre>
<img src="qdgp5.png" class="center">	
<br>
However, the simple Qreg still provides the best linear approximation, to the average conditional quantile effect:
<pre id="stlog-10" class="stlog"><samp><span class="stinp">. qreg y  x , q(10) nolog</span>

.1 Quantile regression                              Number of obs = <span class="stres">     1,000</span>
  Raw sum of deviations<span class="stres"> 55.68722</span> (about <span class="stres">-.34313792</span>)
  Min sum of deviations<span class="stres"> 48.61814                    </span>Pseudo R2     = <span class="stres">    0.1269</span>

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |<span class="stres">  -.1634042   .0211613    -7.72   0.000    -.2049299   -.1218786</span>
       _cons |<span class="stres">   -.106545   .0371668    -2.87   0.004    -.1794791   -.0336109</span>
------------------------------------------------------------------------------

<span class="stinp">. qui:qreg y  x d2 , q(10)</span>

<span class="stinp">. f_able d2, auto</span>
This is an experimental feature in f_able
Using this option, you do not need to add <span class="stres">nochain</span> or <span class="stres">numerical</span> options in margins
All variables in -nlvar- have been declared

<span class="stinp">. margins, dydx(x)</span>

Average marginal effects                        Number of obs     = <span class="stres">     1,000</span>
Model VCE    : <span class="stres">IID</span>

Expression   : <span class="stres">Linear prediction, predict()</span>
dy/dx w.r.t. : <span class="stres">x</span>

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |<span class="stres">  -.1585367   .0096202   -16.48   0.000    -.1773918   -.1396815</span>
------------------------------------------------------------------------------

<span class="stinp">. qreg y  x , q(90) nolog</span>

.9 Quantile regression                              Number of obs = <span class="stres">     1,000</span>
  Raw sum of deviations<span class="stres"> 57.53462</span> (about <span class="stres">.36839858</span>)
  Min sum of deviations<span class="stres"> 49.29308                    </span>Pseudo R2     = <span class="stres">    0.1432</span>

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |<span class="stres">   .1680959    .019872     8.46   0.000     .1291002    .2070915</span>
       _cons |<span class="stres">   .1167802   .0349024     3.35   0.001     .0482897    .1852707</span>
------------------------------------------------------------------------------

<span class="stinp">. qui:qreg y  x d2 , q(90)</span>

<span class="stinp">. f_able d2, auto</span>
This is an experimental feature in f_able
Using this option, you do not need to add <span class="stres">nochain</span> or <span class="stres">numerical</span> options in margins
All variables in -nlvar- have been declared

<span class="stinp">. margins, dydx(x)</span>

Average marginal effects                        Number of obs     = <span class="stres">     1,000</span>
Model VCE    : <span class="stres">IID</span>

Expression   : <span class="stres">Linear prediction, predict()</span>
dy/dx w.r.t. : <span class="stres">x</span>

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |<span class="stres">   .1488343   .0078141    19.05   0.000      .133519    .1641497</span>
------------------------------------------------------------------------------
</samp></pre>
<h2>Conclusion</h2>
In this post, I provided you with some code that I hope you find helpful to simulate and better understand what kind of information CQR can identify, and understand the implications of the rank invariance assumption. 
<br><br>
There is still the problem of How should one interpret these results. 
<br><br>
Interpreting CQR is a problem on its own. I'm still writing part III on the interpretation of QREG models, which emphasizes some of the details I describe here. So, yes, that is still to come.
<br><br>
As always, thank you for reading. Comments or questions, welcome. 
<br><br>
And if you want the code for the data above, you can find it <a href="qreg_sim_strip.do">Here</a>
</body>
</html>
