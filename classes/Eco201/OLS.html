<!DOCTYPE html>
<html lang="en"><head>
<script src="OLS_files/libs/clipboard/clipboard.min.js"></script>
<script src="OLS_files/libs/quarto-html/tabby.min.js"></script>
<script src="OLS_files/libs/quarto-html/popper.min.js"></script>
<script src="OLS_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="OLS_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="OLS_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="OLS_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.269">

  <meta name="author" content="Fernando Rios-Avila">
  <title>Linear Regression Model</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="OLS_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="OLS_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="OLS_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="OLS_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="OLS_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="OLS_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="OLS_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Linear Regression Model</h1>
  <p class="subtitle">Statistical Inference and Extensions</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Fernando Rios-Avila 
</div>
</div>
</div>

</section>
<section id="introduction" class="slide level2 smaller">
<h2>Introduction</h2>
<ul>
<li><p>Linear Regression (usually estimated via OLS) is the most basic, and still most useful, tool for analyzing data.</p></li>
<li><p>The goal is to find what the relationship between the outcome <span class="math inline">\(y\)</span> and explanatory variables <span class="math inline">\(X's\)</span> is.</p></li>
<li><p>Say that we start with a very simple “<strong><em>model</em></strong>” that states tries to describe the population function as the following:</p></li>
</ul>
<p><span class="math display">\[
y = h(X,\varepsilon)
\]</span></p>
<p>Here, <span class="math inline">\(X\)</span> represents a set of observed covariates and <span class="math inline">\(\varepsilon\)</span> the set of unobserved characteristics, and for now, we assume that there is no pre-define relationship between these components.</p>
<ul>
<li>For now, we will make standard exogeneity assumptions for the identification of the model</li>
</ul>
</section>
<section id="estimation" class="slide level2 smaller">
<h2>Estimation</h2>
<ul>
<li>The functional form, however, is unknowable. However, under the <strong><em>small</em></strong> assumption that <span class="math inline">\(X\)</span> and <span class="math inline">\(\varepsilon\)</span> are unrelated, if we would have access to the population data, we could instead consider the Conditional Expectation function (CEF):</li>
</ul>
<p><span class="math display">\[
E(y_i|X_i=x) = \int t f_y(t|X_i=x)dx
\]</span></p>
<ul>
<li><p>Notice that this implies a fully <strong>non-parametric</strong> estimation of the Linear function (because it does not impose any functional form).</p></li>
<li><p>With this, we can “decompose” the outcome <span class="math inline">\(y\)</span> into two components, one that depends on observation characteristics (CEF) and one that depends on the error <span class="math inline">\(\varepsilon\)</span>.</p></li>
</ul>
<p><span class="math display">\[
y = E(y|X) + \varepsilon
\]</span></p>
<ul>
<li>This has the nice property that the error is unrelated to any functional form of <span class="math inline">\(X\)</span>, while providing a summary of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>.</li>
</ul>
</section>
<section id="section" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>The CEF is a convenient abstract, but to estimate it, we require assumptions. (Recall the assumptions for unbiased OLS?)</p></li>
<li><p>Namely, we need to impose a linearity assumption, namely:</p></li>
</ul>
<p><span class="math display">\[
E(y_i|X_i=x) = \beta_0 + \beta_1 x_1 +\beta_2 x_2 + ... +
\beta_k x_k = X_i'\beta
\]</span></p>
<ul>
<li><p>And the solution for <span class="math inline">\(\beta\)</span> is given by:</p>
<p><span class="math display">\[
\beta = \underset{b}{arg} \ E(L(y_i-X'_i b))
\]</span></p>
<p>Where the loss function <span class="math inline">\(L(x)=x^2\)</span>. (Square loss function)</p></li>
<li><p>This implies the following condition:</p></li>
</ul>
<p><span class="math display">\[
E[X_i (y_i-X_i'b)]=0 \rightarrow \beta = E[X_i'X_i]^{-1}E[X_i'y_i]
\]</span></p>
<ul>
<li>This population terms must be substituted by the sample equivalent: <span class="math inline">\(E(X_i) =\frac{1}{N} \sum_i^NX_i\)</span></li>
</ul>
</section>
<section id="mata-ols-estimator" class="slide level2 smaller">
<h2>Mata: OLS Estimator</h2>
<p>The estimator using Sample equivalents become:</p>
<p><span class="math display">\[
\hat \beta =
\left(\frac{1}{N} \sum_i X_i'X_i \right)^{-1}
\frac{1}{N} \sum_i X_i'y_i=(X'X)^{-1}X'y
\]</span></p>
<div class="sourceCode" id="cb1" style="font-size: 150%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb1-1"><a href="#cb1-1"></a>frause oaxaca, <span class="kw">clear</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">keep</span> <span class="kw">if</span> lnwage !=.</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">mata</span>:</span>
<span id="cb1-4"><a href="#cb1-4"></a>  <span class="fu">y</span> = st_data(.,<span class="st">"lnwage"</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a>  n = <span class="bn">rows</span>(<span class="fu">y</span>)</span>
<span id="cb1-6"><a href="#cb1-6"></a>  x = st_data(.,<span class="st">"female age educ"</span>),<span class="fu">J</span>(n,1,1)</span>
<span id="cb1-7"><a href="#cb1-7"></a>  exx = <span class="kw">cross</span>(x,x)/n</span>
<span id="cb1-8"><a href="#cb1-8"></a>  exy = <span class="kw">cross</span>(x,<span class="fu">y</span>)/n</span>
<span id="cb1-9"><a href="#cb1-9"></a>  b   = <span class="fu">invsym</span>(exx)*exy</span>
<span id="cb1-10"><a href="#cb1-10"></a>  b</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">end</span>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="inference---distribution-of-betas" class="slide level2 smaller">
<h2>Inference - Distribution of <span class="math inline">\(\beta's\)</span></h2>
<p>so: <span class="math display">\[
y = X\beta + \varepsilon
\\
\sqrt N (\hat\beta - \beta) =\frac{1}{N}\Big[\sum (X_iX_i')\Big]^{-1} \frac{1}{\sqrt N} \sum(X_i\varepsilon_i)
\]</span></p>
<ul>
<li><p>Here <span class="math inline">\(\varepsilon\)</span> is the true population error. <span class="math inline">\(\hat\beta\)</span> is unbiased if the second term has an expectation of Zero. (the error is independent from <span class="math inline">\(X\)</span>).</p></li>
<li><p>Asymptotically, the first term is assumed fixed <span class="math inline">\(E(X_i X_i')\)</span>. And, because <span class="math inline">\(E(X_i\varepsilon)=0\)</span>, and <span class="math inline">\(\frac{1}{\sqrt N} \sum(X_i\varepsilon)\)</span> is normalized, by CLT we have that:</p></li>
</ul>
<p><span class="math display">\[
\sqrt N (\hat\beta-\beta)\sim N(0,E(X_iX_i')^{-1} \ E(X_iX_i'\varepsilon ^2) \ E(X_iX_i')^{-1}
)
\]</span></p>
<ul>
<li>From here, the main question is : How do we estimate <span class="math inline">\(E(X_iX'\varepsilon_i^2)\)</span>?</li>
</ul>
</section>
<section id="inference-estimating-se" class="slide level2 smaller">
<h2>Inference: Estimating SE</h2>
<ul>
<li>Lets First Rewrite the last expression:</li>
</ul>
<p><span class="math display">\[
Var(\hat\beta)=(X'X)^{-1} X'\Omega X (X'X)^{-1}
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\Omega=
\left(
\begin{matrix}
\sigma_1^2 &amp; \sigma_{12} &amp;  ... &amp; \sigma_{1N}\\
\sigma_{21} &amp; \sigma_{2}^2 &amp; ... &amp; \sigma_{2N} \\
...&amp;...&amp;...&amp;...\\
\sigma_{N1} &amp; \sigma_{N2} &amp; ... &amp; \sigma_{NN}^2 \\
\end{matrix}
\right)
\]</span></p>
<p>In other words, the variance of <span class="math inline">\(\hat\beta\)</span> allows for arbitrary relationship among the errors, as well as heteroskedasticity. This, however is impossible to estimate!, thus we require assumptions</p>
</section>
<section id="homoskedasticity-and-independent-samples" class="slide level2 smaller">
<h2>Homoskedasticity and independent samples</h2>
<p>The easiest route is to assume homoskedastic errors <span class="math inline">\(\sigma^2 = \sigma_i^2 \ \forall i \in 1,...,N\)</span> . (the error is spread equally around the mean)</p>
<p>With independent samples <span class="math inline">\(\sigma_{ij}=0 \ \forall \ i\neq j\)</span> . (A persons unobserved is completely independent from anybody else)</p>
<p><span class="math display">\[
\Omega_00=
\left(
\begin{matrix}
\sigma_1^2 &amp; \sigma_{12} &amp;  ... &amp; \sigma_{1N}\\
\sigma_{21} &amp; \sigma_{2}^2 &amp; ... &amp; \sigma_{2N} \\
...&amp;...&amp;...&amp;...\\
\sigma_{N1} &amp; \sigma_{N2} &amp; ... &amp; \sigma_{NN}^2 \\
\end{matrix}
\right)=I(N)*\sigma^2
\]</span></p>
<p>Thus <span class="math display">\[
Var(\hat\beta)_{00}=(X'X)^{-1} X'I(N)\sigma^2 X (X'X)^{-1}=\sigma^2 (X'X)^{-1} \\
\sigma^2 = E(\varepsilon^2)
\]</span></p>
<div class="sourceCode" id="cb2" style="font-size: 150%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb2-1"><a href="#cb2-1"></a>err = <span class="fu">y</span>:-x*b</span>
<span id="cb2-2"><a href="#cb2-2"></a>var_b_000 = <span class="kw">mean</span>(err:^2) * <span class="fu">invsym</span>(x'x)</span>
<span id="cb2-3"><a href="#cb2-3"></a>b,<span class="fu">sqrt</span>(diagonal(var_b_00))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section class="slide level2">

<p>But, <span class="math inline">\(\sigma^2\)</span> is not known, so we have to use <span class="math inline">\(\hat\sigma^2\)</span> instead, which depends on the sample residuals: <span class="math display">\[\hat\sigma^2 = \frac{1}{N-k-1}\sum \hat e^2
\]</span> Where we account for the fact true errors are not observed, but rather residuals are estimated, adjusting the degrees of freedom.</p>
<div class="sourceCode" id="cb3" style="font-size: 150%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">N</span> = <span class="bn">rows</span>(<span class="fu">y</span>); <span class="kw">k</span> = <span class="bn">cols</span>(x)</span>
<span id="cb3-2"><a href="#cb3-2"></a>var_b_00 = <span class="kw">sum</span>(err:^2)/(<span class="kw">N</span>-<span class="kw">k</span>) * <span class="fu">invsym</span>(x'x)</span>
<span id="cb3-3"><a href="#cb3-3"></a>b,<span class="fu">sqrt</span>(diagonal(var_b_00))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="lifting-assumptions-heteroscedasticity" class="slide level2 smaller">
<h2>Lifting Assumptions: Heteroscedasticity</h2>
<ul>
<li>We start by lifting this assumption, which implies the following:</li>
</ul>
<p><span class="math display">\[
\sigma^2_i \neq \sigma^2_j \  \forall \ i\neq j
\]</span> But to estimate this, we need an approximation for <span class="math inline">\(\sigma^2_i = E(\varepsilon_i^2) = \varepsilon_i^2\)</span>.</p>
<ul>
<li>With this, we can obtain what is known as th White or Eicker-White or Heteroskedasiticy Robust Standard errors.</li>
</ul>
<p><span class="math display">\[
Var(\hat\beta)_{0} = (X'X)^{-1} (X\hat e)'(\hat eX) (X'X)^{-1} \\
=(X'X)^{-1} \sum(X_iX_i'\hat e^2) (X'X)^{-1}
\]</span> Which imposes <strong>NO</strong> penalty to the fact that we are using residuals not errors. If we account for that however, we obtain what is known as HC1, SE, the standard in <code>stata</code>. (when you type <code>robust</code>) <span class="math display">\[
Var(\hat\beta)_{1}=\frac{N}{N-K-1}Var(\hat\beta)_{0}
\]</span></p>
<div class="sourceCode" id="cb4" style="font-size: 150%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb4-1"><a href="#cb4-1"></a>ixx = <span class="fu">invsym</span>(x'x))</span>
<span id="cb4-2"><a href="#cb4-2"></a>var_b_0 = ixx * (x:*<span class="fu">e</span>)'(x:*<span class="fu">e</span>) * ixx</span>
<span id="cb4-3"><a href="#cb4-3"></a>var_b_1 = <span class="kw">N</span>/(<span class="kw">N</span>-<span class="kw">k</span>)*var_b_0</span>
<span id="cb4-4"><a href="#cb4-4"></a>b,<span class="fu">sqrt</span>(diagonal(var_b_0)),<span class="fu">sqrt</span>(diagonal(var_b_1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="but-error-is-not-the-same-as-residual" class="slide level2 smaller">
<h2>But error is not the same as residual!</h2>
<p>A residual is model dependent, and should not be confused with the model error <span class="math inline">\(\hat \varepsilon \neq \varepsilon\)</span>. Because of this, additional corrections are needed to obtained unbiased <span class="math inline">\(var(\hat\beta)\)</span> estimates. (Degrees of freedom). But other options exists.</p>
<p>Redefine the Variance Formula:</p>
<p><span class="math display">\[
Var(\hat\beta)=(X'X)^{-1} (\sum X_iX_i \psi_i )  (X'X)^{-1}
\]</span> From here Mackinnon and White (1985) suggest few other options: <span class="math display">\[
\begin{matrix}
HC0: \psi_i = \hat e^2 &amp;
HC1: \psi_i = \frac{N}{N-K}  \hat e^2 \\
HC2: \psi_i =   \hat e^2 \frac{1}{1-h_{ii}} &amp;
HC3: \psi_i =   \hat e^2 \frac{1}{(1-h_{ii})^2}
\end{matrix}
\]</span> Where <span class="math inline">\(h_{ii}\)</span> is the ith diagonal element of <span class="math inline">\(X(X'X)^{-1}X'\)</span> and allows you to see how dependent a model is to a single observation.</p>
<p>HC2 and HC3 Standard errors are better than HC1 SE, specially when Samples are small.</p>
<blockquote>
<p>NOTE: this <span class="math inline">\(h_{ii}\)</span> element is also used to measure the degrees of freedom of a model. Sum it up, and you will see!.</p>
</blockquote>
</section>
<section id="coding-robust-se" class="slide level2">
<h2>Coding Robust SE</h2>
<div class="sourceCode" id="cb5" style="font-size: 100%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">// h = diagonal(X invsym(X'x) X') Wrong Way, too many calculations</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw">h</span> = rowsum(x*<span class="fu">invsym</span>(x'x):*x)</span>
<span id="cb5-3"><a href="#cb5-3"></a>psi0 = <span class="fu">e</span>:^2           ;   psi1 = <span class="fu">e</span>:^2*<span class="kw">N</span>/(<span class="kw">N</span>-<span class="kw">k</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a>psi2 = <span class="fu">e</span>:^2:/(1:-<span class="kw">h</span>)   ;   psi3 = <span class="fu">e</span>:^2:/((1:-<span class="kw">h</span>):^2)</span>
<span id="cb5-5"><a href="#cb5-5"></a>var_b_0 = ixx * <span class="kw">cross</span>(x,psi0,x) * ixx</span>
<span id="cb5-6"><a href="#cb5-6"></a>var_b_1 = ixx * <span class="kw">cross</span>(x,psi1,x) * ixx</span>
<span id="cb5-7"><a href="#cb5-7"></a>var_b_2 = ixx * <span class="kw">cross</span>(x,psi2,x) * ixx</span>
<span id="cb5-8"><a href="#cb5-8"></a>var_b_3 = ixx * <span class="kw">cross</span>(x,psi3,x) * ixx</span>
<span id="cb5-9"><a href="#cb5-9"></a>b,<span class="fu">sqrt</span>(diagonal(var_b_0)),<span class="fu">sqrt</span>(diagonal(var_b_1)),</span>
<span id="cb5-10"><a href="#cb5-10"></a>  <span class="fu">sqrt</span>(diagonal(var_b_2)),<span class="fu">sqrt</span>(diagonal(var_b_3))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or in <code>Stata</code>:</p>
<div class="sourceCode" id="cb6" style="font-size: 100%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">regress</span> <span class="fu">y</span> x1 <span class="kw">x2</span> x3, <span class="kw">vce</span>(<span class="kw">robust</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">regress</span> <span class="fu">y</span> x1 <span class="kw">x2</span> x3, <span class="kw">vce</span>(hc2)</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="kw">regress</span> <span class="fu">y</span> x1 <span class="kw">x2</span> x3, <span class="kw">vce</span>(hc3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="lifting-even-more-assumptions-correlation" class="slide level2 smaller">
<h2>Lifting Even more Assumptions: Correlation</h2>
<ul>
<li><p>One assumption we barely consider last semester was the possibility that errors could be correlated within groups. (except for time series and serial correlation)</p></li>
<li><p>For example, families may share similar unobserved factors, So would people interviewed from the same classroom, cohort, city, etc. There could be many dimensions to consider possible correlations!</p></li>
<li><p>In that situation, we may be missmeasuring the magnitude of the errors (probably downward), because the <span class="math inline">\(\Omega\)</span> is no longer diagonal: <span class="math inline">\(\sigma_{ij} \neq 0\)</span> for some <span class="math inline">\(i\neq j\)</span>.</p>
<ul>
<li>But, estimate all parameters in an NxN matrix is unfeasible. We need assumptions!</li>
</ul></li>
<li><p>Say we have <span class="math inline">\(G\)</span> groups <span class="math inline">\(g=(1…G)\)</span> . We can rewrite the expression for <span class="math inline">\(\hat\beta\)</span> as follows:</p></li>
</ul>
<p><span class="math display">\[
\hat\beta-\beta = (X'X)^{-1}\sum_{g=1}^G X'_g \varepsilon_g=
(X'X)^{-1}\sum_{g=1}^G s_g
\]</span></p>
<ul>
<li>We can assume that individuals are correlated within groups <span class="math inline">\(E(s_g's_g) =\Sigma_g\)</span> , but they are uncorrelated across groups <span class="math inline">\(E(s_g s'_{g')=0 \ \forall \ g \neq g'\)</span> .</li>
<li>These groups are typically known as “<strong>clusters</strong>”</li>
</ul>
</section>
<section id="addressing-correlation" class="slide level2 smaller">
<h2>Addressing Correlation</h2>
<ul>
<li>The idea of correcting for clusters is pretty simple. We just need to come up with an estimator for <span class="math inline">\(\Sigma_g\)</span> for every cluster, so that:</li>
</ul>
<p><span class="math display">\[Var(\hat\beta) = (X'X)^{-1} \left( \sum_{g=1}^N \Sigma_g \right) (X'X)^{-1} \\
\Sigma_g = E( X_g' \Omega_g X_g) \]</span></p>
<ul>
<li><p>Here <span class="math inline">\(\Omega_g\)</span> should be an approximation of the variance covariance matrix among the errors of ALL individuals that belong to the same cluster. But how do we approximate it?</p></li>
<li><p>As with the EW - HC standard errors, there are many ways to estimate Clustered Standard errors. See MacKinnon et al (2023) for reference. We will refer only to the simpler ones CV0 and CV1.</p></li>
</ul>
<blockquote>
<p>Still How?</p>
</blockquote>
<ul>
<li>Recall we approximate <span class="math inline">\(\sigma^2_i\)</span> with <span class="math inline">\(\varepsilon_i^2\)</span>. Then we can approximate <span class="math inline">\(\sigma_{ij}\)</span> with <span class="math inline">\(\varepsilon_j \varepsilon_i\)</span>. More specifically:</li>
</ul>
<p><span class="math display">\[ \Omega_g \simeq \varepsilon \varepsilon' \ or \ \Sigma_g = X'_g \varepsilon \varepsilon' X_g = (X'_g \varepsilon) (\varepsilon' X_g) \]</span></p>
<ul>
<li>Change <span class="math inline">\(\varepsilon\)</span> with <span class="math inline">\(\hat\varepsilon\)</span>, do that for every group, and done! (almost).</li>
</ul>
</section>
<section id="section-1" class="slide level2 smaller">
<h2></h2>
<ul>
<li>As mentioned earlier, there are many CCSE (clustered consistent SE).</li>
</ul>
<p><span class="math display">\[
CV_0 = (X'X)^{-1} \sum_{g=1}^G \hat \Sigma_g (X'X)^{-1} \\
CV_1 = \frac{G(N-1)}{(G-1)(N-k-1)}(X'X)^{-1} \sum_{g=1}^G \hat \Sigma_g (X'X)^{-1}
\]</span></p>
<ul>
<li>Similar to HC. CV0 does not correct for degrees of freedom. CV1, however, accounts for Degrees of freedom in the model, and clusters.</li>
</ul>
<div class="sourceCode" id="cb7" style="font-size: 120%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb7-1"><a href="#cb7-1"></a><span class="co">// 1st Sort Data (easier in Stata rather than Mata) and reload</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="fu">y</span>   = st_data(.,<span class="st">"lnwage"</span>); x   = st_data(.,<span class="st">"educ exper female"</span>),<span class="fu">J</span>(1434,1,1) ; cvar= st_data(.,<span class="st">"isco"</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="fu">e</span>   = <span class="fu">y</span>:-x*b</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">// Set the panel info</span></span>
<span id="cb7-5"><a href="#cb7-5"></a>info = <span class="kw">panelsetup</span>(cvar,1); g=<span class="bn">rows</span>(info); n=<span class="bn">rows</span>(<span class="fu">y</span>)</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">// get X_g'e for all groups: </span></span>
<span id="cb7-7"><a href="#cb7-7"></a>s_xg_e = panelsum(x:*<span class="fu">e</span>,info)</span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">// Sum Sigma_g</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>sigma_g = s_xg_e's_xg_e</span>
<span id="cb7-10"><a href="#cb7-10"></a>cv0 = ixx*sigma_g*ixx</span>
<span id="cb7-11"><a href="#cb7-11"></a>cv1 =g/(g-1)*(n-1)/(n-<span class="kw">k</span>)*ixx*sigma_g*ixx</span>
<span id="cb7-12"><a href="#cb7-12"></a>b,<span class="fu">sqrt</span>(diagonal(cv0)),<span class="fu">sqrt</span>(diagonal(cv1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>or compare it to</p>
<div class="sourceCode" id="cb8" style="font-size: 120%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">reg</span> lnwage educ exper female, <span class="kw">cluster</span>(isco)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="beware-of-over-clustering" class="slide level2 smaller">
<h2>Beware of over-clustering</h2>
<p>While clustering helps address a problem of “intragroup” correlation, it can/should be done with care. It is important to be aware about some unintended problems of using Correlation.</p>
<ol type="1">
<li><p>CV0 and CV1 work well when you have a large number of Clusters. How many? MHE(2009) says…42 (this is like having large enough samples for Asymptotic variance). If # clusters are small, you would do better with other approaches (including CV2 and CV3).</p></li>
<li><p>When you cluster your standard errors, you will “most-likely” generate larger standard errors in your model. Standard recommendation (MHE) is to cluster at the level that makes sense (based on data) and produces largest SE (to be conservative).</p></li>
</ol>

<img data-src="./figures/clse.png" class="r-stretch quarto-figure-center"><p class="caption">Standard Errors</p></section>
<section id="section-2" class="slide level2 smaller">
<h2></h2>
<ol start="3" type="1">
<li><p>You may also consider that clustering does not work well when sample sizes within cluster are to diverse (micro vs macro clusters)</p></li>
<li><p>And there is the case where clustering is required among multiple dimensions (see <code>vcemway</code>). Where the unobserved correlation could be present in different dimensions.</p></li>
</ol>
<p>So what to cluster and how?</p>
<ul>
<li><p>Mackinnon et al (2023) provides a guide on how and when to cluster your standard errors. (some are quite advanced)</p></li>
<li><p>General practice, At least use Robust SE (HC2 or HC3 if sample is small), but use clustered SE for robustness.</p></li>
<li><p>You may want to cluster SE based on some theoretical expectations. Choose -broader- groups for conservative analysis.</p></li>
<li><p>In treatment-causal effect analysis, you may want to cluster at the “treatment” level.</p></li>
</ul>
<blockquote>
<p>But…Beyond hc0/1 and CV0/1 there is not much out there for correcting Standard errors in nonlinear models.</p>
</blockquote>
</section>
<section>
<section id="the-bootstrap" class="title-slide slide level1 center">
<h1>The Bootstrap</h1>

</section>
<section id="if-you-cant-sandwich-you-can-re-sample" class="slide level2 smaller">
<h2>If you can’t Sandwich 🥪, you can re-Sample</h2>
<ul>
<li><p>The discussion above refereed to the estimation of SE using <span class="math inline">\(Math\)</span>. In other words, it was based on the asymptotic properties of the data. Which may not work in small samples.</p></li>
<li><p>An alternative, often used by practitioners, is using re-sampling methods to obtain approximations to the coefficient distributions of interest.</p></li>
</ul>
<p>But… How does it work?🤔</p>
<p>First ask yourself, how does Asymptotic theory work (and econometrics)? 😱</p>
<blockquote>
<p><span class="smallcaps">Note: I recommend reading the -simulation- chapter in The effect, and simulation methods chapter in CT.</span></p>
</blockquote>
</section>
<section id="a-brief-reviewagain" class="slide level2 smaller">
<h2>A Brief Review…again 😇</h2>
<p>If I were to summarize most of the methodologies (ok all) we used last semester, and this one, the properties that have been derived and proofed are based on the assumption that we “could” always get more data (frequentist approach).</p>
<p>There is population (or supper population) from where we can get samples of data.</p>
<ol type="1">
<li><p>We get a sample (<span class="math inline">\(y,X\)</span>) (of size N)</p></li>
<li><p>Estimate our model : <code>method</code>(<span class="math inline">\(y,X\)</span>)<span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\beta's\)</span></p></li>
<li><p>Repeat to infinitum</p></li>
<li><p>Collect all <span class="math inline">\(\beta's\)</span> and summarize. (Mean and Standard deviations)</p></li>
</ol>
<p>Done.</p>
<p>The distributions you get from the above exercise should be the same as what your estimation method produces. (if not, there there is something wrong with the estimation method)</p>
</section>
<section id="but-we-only-get-1-sample" class="slide level2 smaller">
<h2>But we only get 1 Sample!</h2>
<p>The truth is we do not have access to multiple samples. Getting more data, is in fact, very expensive. So what to do ?</p>
<ul>
<li><p>Rely on Asymptotic theory</p></li>
<li><p>learn Bayesian Econometrics 🥺</p></li>
<li><p>or-resample? and do Bootstrap!</p></li>
</ul>
<p><strong>Basic idea of Bootstrapping</strong></p>
<ul>
<li><p>In the ideal scenario, you get multiple samples from your population, Estimate parameters, and done.</p></li>
<li><p>If not possible you do the next best thing. You get your sample (assume is your mini-population),</p>
<ul>
<li><p>Draw subsamples of same size (with replacement) (<span class="math inline">\(y_i^s,X_i^s\)</span>)</p></li>
<li><p>estimate your model and obtain parameters <span class="math inline">\(\beta^s_i\)</span></p></li>
<li><p>Summarize those parameters…and done, you get <span class="math inline">\(Var(\hat\beta)\)</span> for 🆓. (or is it?)</p></li>
</ul></li>
</ul>
</section>
<section id="bootstrapping" class="slide level2 smaller">
<h2>Bootstrapping</h2>
<ul>
<li>👢Bootstrapping is a methodology that allows you to obtain empirical estimations of standard errors making use of the data in hand, and without even knowing about Asymptotic theory (other than how to get means and variances).</li>
</ul>

<img data-src="./figures/bss.png" class="r-stretch quarto-figure-center"><p class="caption">Bootstrap Sample</p><ul>
<li>And of course, it comes in different flavors.</li>
</ul>
</section>
<section id="bootstrap-types" class="slide level2 smaller">
<h2>Bootstrap Types:</h2>
<ul>
<li><p><strong>Non-parametric Bootstrap</strong>: You draw subsamples from the main sample. Each observation has the same pr of being selected.</p>
<ul>
<li><p>Easiest to implement ( <code>see bootstrap:</code>)</p></li>
<li><p>Works in almost all cases, but you may have situations when some covariates are rare.</p></li>
<li><p>Can be extended to allow “clusters” using “block bootstrapping”. Works best if re-sampling “follows” the same sampling structure as your sample.</p></li>
</ul></li>
<li><p><strong>Parametric Bootstrap:</strong> You estimate your model, make assumptions of your model error.</p>
<ul>
<li><p>You need to implement it on your own. <span class="math inline">\(y^s=x\hat b+\tilde e\)</span> for <span class="math inline">\(\tilde e \sim f(\hat \theta)\)</span></p></li>
<li><p>It will not work well if the assumptions of the error modeling are wrong.</p></li>
</ul></li>
<li><p><strong>Residual bootstrap:</strong> Estimate your model, obtain residuals. Re-sample residuals</p>
<ul>
<li>Again, implement it on your own. <span class="math inline">\(y^s = x\hat b+\tilde e\)</span> for <span class="math inline">\(\tilde e \sim {\hat e_1 , ... , \hat e_N}\)</span></li>
<li>It depends even more on the assumptions of the error modeling.</li>
</ul></li>
</ul>
</section>
<section id="section-3" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p><strong>UWild bootstrap</strong>: Estimate your model, obtain residuals, and re-sample residual weights.</p>
<ul>
<li><p>Again…on your own: <span class="math inline">\(y^s = x\hat b +\hat e * v\)</span> , where <span class="math inline">\(v \sim ff()\)</span> where <span class="math inline">\(ff()\)</span> is a “good” distribution function. <span class="math inline">\(E(v)=0 \ \&amp; \ Var(v)=1\)</span></p></li>
<li><p>Actually quite flexible, and works well under heteroskedasticity!</p></li>
<li><p>It can also allow clustered standard errors. The error <span class="math inline">\(v\)</span> no longer changes by individual, but by group. It also works well with weights.</p></li>
</ul></li>
<li><p><strong>UWild bootstrap-2</strong> : Estimate your model, obtain Influence functions 😱 , and re-sample residual weights.</p>
<ul>
<li>This is an extension to the previous option. But with advantages
<ul>
<li><p>you do not need to -reestimate- the model. Just look into how the the mean of IF’s change.</p></li>
<li><p>it can be applied to linear and nonlinear model (if you know how to build the IF’s)</p></li>
</ul></li>
<li>Works well with clustered and weights.</li>
</ul></li>
<li><p><strong>CWild bootstrap:</strong> Similar UWild Bootstrap, Obtain Influence functions under the Null (imposing restrictions), and use that to test the NULL.</p>
<ul>
<li><p>No, you do not need to do it on your own. <code>see bootest</code> in <code>Stata</code>.</p></li>
<li><p>Works pretty well with small samples and small # clusters. Probably the way to go if you really care about Standard errors.</p></li>
</ul></li>
</ul>
</section>
<section id="how-to-bootstrap-in-stata" class="slide level2">
<h2>How to Bootstrap? in <code>Stata</code></h2>
<p>I have a few notes on Bootstrapping here <a href="https://friosavila.github.io/playingwithstata/main_bootstrap.html">Bootstrapping in Stata</a>. But let me give you the highlights for the most general case.</p>
<ol type="1">
<li><p>Most (if not all commands) in <code>Stata</code> allow you to obtain bootstrap standard errors, by default. see:<code>help [cmd]</code></p>
<p>they usually have the following syntax:</p>
<div class="sourceCode" id="cb9" style="font-size: 120%"><pre class="sourceCode numberSource Stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb9-1"><a href="#cb9-1"></a>[cmd] <span class="fu">y</span> x1 <span class="kw">x2</span> x3, <span class="kw">vce</span>(<span class="kw">bootstrap</span>, options)</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="kw">regress</span> lnwage educ exper female, <span class="kw">vce</span>(<span class="kw">bootstrap</span>, reps(100))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>However, you can also Bootstrap that commands that do not have their own <code>bootstrap</code> option.</p>
<div class="sourceCode" id="cb10" style="font-size: 120%"><pre class="sourceCode numberSource Stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">bootstrap</span>:[cmd] <span class="fu">y</span> x1 <span class="kw">x2</span> x3, </span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">bootstrap</span>, reps(100):<span class="kw">regress</span> lnwage educ exper female</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="kw">bootstrap</span>, reps(100) <span class="kw">cluster</span>(isco):<span class="kw">regress</span> lnwage educ exper female</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="section-4" class="slide level2 smaller">
<h2></h2>
<ol start="3" type="1">
<li><p>This last command may allow you to bootstrap multiple models at the same time, although it does require a bit of programming. (and a do file)</p>
<div class="sourceCode" id="cb11" style="font-size: 120%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">gen</span> tchild = kids6 + kids714</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="kw">program</span> bs_wages_children, <span class="kw">eclass</span> <span class="co">// eclass is for things like equations</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>  ** Estimate first <span class="kw">model</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>  <span class="kw">reg</span> lnwage educ exper female</span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="fu">matrix</span> b1 = <span class="fu">e</span>(b)</span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="fu">matrix</span> <span class="ot">coleq</span> b1 = lnwage</span>
<span id="cb11-7"><a href="#cb11-7"></a>  ** Estimate second <span class="kw">model</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>  <span class="kw">reg</span> tchild educ exper female</span>
<span id="cb11-9"><a href="#cb11-9"></a>  <span class="fu">matrix</span> b2 = <span class="fu">e</span>(b)</span>
<span id="cb11-10"><a href="#cb11-10"></a>  <span class="fu">matrix</span> <span class="ot">coleq</span> b2 = tchild</span>
<span id="cb11-11"><a href="#cb11-11"></a>  ** Put things together and <span class="kw">post</span></span>
<span id="cb11-12"><a href="#cb11-12"></a>  <span class="fu">matrix</span> b = b1 , b2</span>
<span id="cb11-13"><a href="#cb11-13"></a>  <span class="kw">ereturn</span> <span class="kw">post</span> b</span>
<span id="cb11-14"><a href="#cb11-14"></a><span class="kw">end</span></span>
<span id="cb11-15"><a href="#cb11-15"></a></span>
<span id="cb11-16"><a href="#cb11-16"></a><span class="kw">gen</span> tchild = kids6 + kids714</span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a>.  <span class="kw">bootstrap</span>: bs_wages_children</span>
<span id="cb11-19"><a href="#cb11-19"></a>(running bs_wages_children <span class="kw">on</span> estimation <span class="kw">sample</span>)</span>
<span id="cb11-20"><a href="#cb11-20"></a></span>
<span id="cb11-21"><a href="#cb11-21"></a>warning: ... </span>
<span id="cb11-22"><a href="#cb11-22"></a></span>
<span id="cb11-23"><a href="#cb11-23"></a>Bootstrap replications (50)</span>
<span id="cb11-24"><a href="#cb11-24"></a>----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 </span>
<span id="cb11-25"><a href="#cb11-25"></a>..................................................    50</span>
<span id="cb11-26"><a href="#cb11-26"></a></span>
<span id="cb11-27"><a href="#cb11-27"></a></span>
<span id="cb11-28"><a href="#cb11-28"></a>Bootstrap results                                        Number <span class="kw">of</span> <span class="kw">obs</span> = 1,434</span>
<span id="cb11-29"><a href="#cb11-29"></a>                                                         Replications  =    50</span>
<span id="cb11-30"><a href="#cb11-30"></a></span>
<span id="cb11-31"><a href="#cb11-31"></a>------------------------------------------------------------------------------</span>
<span id="cb11-32"><a href="#cb11-32"></a>             |   Observed   Bootstrap                         Normal-based</span>
<span id="cb11-33"><a href="#cb11-33"></a>             | coefficient  <span class="fu">std</span>. err.      z    P&gt;|z|     [95% conf. interval]</span>
<span id="cb11-34"><a href="#cb11-34"></a>-------------+----------------------------------------------------------------</span>
<span id="cb11-35"><a href="#cb11-35"></a>lnwage       |</span>
<span id="cb11-36"><a href="#cb11-36"></a>        educ |   .0858252   .0064645    13.28   0.000      .073155    .0984954</span>
<span id="cb11-37"><a href="#cb11-37"></a>       exper |   .0147343   .0015455     9.53   0.000     .0117051    .0177635</span>
<span id="cb11-38"><a href="#cb11-38"></a>      female |  -.0949227   .0228663    -4.15   0.000    -.1397399   -.0501056</span>
<span id="cb11-39"><a href="#cb11-39"></a>       <span class="dt">_cons</span> |    2.21885   .0910609    24.37   0.000     2.040374    2.397326</span>
<span id="cb11-40"><a href="#cb11-40"></a>-------------+----------------------------------------------------------------</span>
<span id="cb11-41"><a href="#cb11-41"></a>tchild       |</span>
<span id="cb11-42"><a href="#cb11-42"></a>        educ |   .0177854   .0088262     2.02   0.044     .0004863    .0350844</span>
<span id="cb11-43"><a href="#cb11-43"></a>       exper |  -.0047747   .0019204    -2.49   0.013    -.0085386   -.0010108</span>
<span id="cb11-44"><a href="#cb11-44"></a>      female |  -.1306332   .0477117    -2.74   0.006    -.2241464     -.03712</span>
<span id="cb11-45"><a href="#cb11-45"></a>       <span class="dt">_cons</span> |   .4163459   .1036883     4.02   0.000     .2131206    .6195712</span>
<span id="cb11-46"><a href="#cb11-46"></a>------------------------------------------------------------------------------</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p>Why does it matter? because you may want to test coefficients individually, or across models. This is only possible if the FULL system is estimated jointly</p>
</section>
<section id="final-words-on-bootstrap" class="slide level2 smaller">
<h2>Final words on Bootstrap:</h2>
<p>So bootstrap (and its many flavors) are convenient approaches to estimate standard errors and elaborate statistical Inference, but its not infallible.</p>
<ol type="1">
<li>If the re-sampling process does not simulate the true sampling design, we may miss important information when constructing SE.</li>
<li>When the parameters are estimated using “hard” cutoffs or restricted distributions, it may not produce good approximations for SE.</li>
<li>You usually require MANY repetitions (standard = 50, but you probably want 999 or more). The more the better, but has some computational costs. (specially simple bs)</li>
<li>Some methods play better with weighted samples, clusters, and other survey designs than others. And some require more know-how than others.</li>
</ol>
<p>So choose your 🔫weapon wisely!</p>
</section></section>
<section>
<section id="small-diversion-the-delta-method" class="title-slide slide level1 center">
<h1>Small Diversion 🦌: The Delta Method</h1>

</section>
<section id="variance-of-nonlinear-functions" class="slide level2 smaller">
<h2>Variance of nonlinear functions</h2>
<div>
<ul>
<li class="fragment"><p>Some times (perhaps not with simple OLS) you many need to estimate Standard errors for transformations of your main coefficient of interest, or combinations of those coefficients.</p></li>
<li class="fragment"><p>Say that you estimated <span class="math inline">\(\theta \sim N(\mu_\theta, \sigma^2_\theta)\)</span> but are interested in the distribution of <span class="math inline">\(g(\theta)\)</span>. How do you do this?</p></li>
<li class="fragment"><p>Two options:</p>
<ol type="a">
<li class="fragment">you re estimate <span class="math inline">\(g(\theta\)</span>) instead, or</li>
<li class="fragment">you make an approximation, using the <strong>Delta Method</strong></li>
</ol></li>
<li class="fragment"><p>How does it work?<br>
</p></li>
</ul>
</div>
</section>
<section id="section-5" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>The <strong>Delta method</strong> uses the linear approximations to approximate the distribution of otherwise not known distributions.</p></li>
<li><p>Further, It relies on the fact that linear transformations a normal distribution, is on itself normal. For example:</p>
<p><span class="math display">\[
g(\hat \theta) \simeq g(\theta) + g'(\hat\theta) (\hat \theta-\theta)
\]</span></p></li>
<li><p>This states that the nonlinear function <span class="math inline">\(g(\theta)\)</span> can be “locally” approximated as a linear function in the neighborhood of <span class="math inline">\(g(\theta)\)</span>.</p></li>
<li><p>Predictions above or below are approximated using the slope of the function. <span class="math inline">\(g'(\theta)\)</span>.</p></li>
<li><p>So, if we take the variance, we get:</p>
<p><span class="math display">\[
Var(g(\hat \theta)) \simeq  Var \left(g(\theta)+ g'(\hat\theta) (\hat \theta-\theta)\right)
=g'(\hat\theta)^2 Var(\theta)
\]</span></p></li>
</ul>
</section>
<section id="delta-method-visualization" class="slide level2">
<h2>Delta Method: Visualization</h2>

<img data-src="./figures/dm.png" class="r-stretch"></section>
<section id="section-6" class="slide level2">
<h2></h2>
<p>It can go multivariate as well:<br>
<span class="math display">\[ g(\hat \theta, \hat \gamma)-g(\theta,\gamma) \simeq N(0,\nabla g ' \Sigma \nabla g) \\
\nabla g ' =   [\begin{matrix}
    dg/d\theta &amp; dg/d\gamma
  \end{matrix}]
\]</span></p>
</section>
<section id="so-why-do-we-care" class="slide level2 smaller">
<h2>So why do we care:</h2>
<p>Two reasons:</p>
<ul>
<li><p>Nonlinear models need this kind of approximations to do statistical inference (probit/logit)</p></li>
<li><p>Recall that when using Robust Standard errors Joint hypothesis Should be done with Care…</p></li>
</ul>
<p>Consider a linear set of restrictions imposed by the <span class="math inline">\(H_0: R\beta = r\)</span>.</p>
<ol type="1">
<li>Estimate the Variance of <span class="math inline">\(R\beta\)</span></li>
</ol>
<p><span class="math display">\[
Var(R\beta)  = \nabla (R\beta)' Var(\beta) R \nabla (R\beta)'= R' Var(\beta) R
\]</span></p>
<ol start="2" type="1">
<li>Estimate the F value for the Linear Hypothesis (Wald Test)</li>
</ol>
<p><span class="math display">\[
(R\hat \beta-r)' Var(R\beta)^{-1} (R\hat \beta-r)/Q \sim F(Q,N-K)
\]</span></p>
</section></section>
<section>
<section id="linear-model-selection-and-regularization" class="title-slide slide level1 center">
<h1>Linear Model Selection and Regularization</h1>

<img data-src="https://www.atakanekiz.com/en/technical/understanding-lasso-and-ridge-regression/featured.jpg" class="r-stretch quarto-figure-center"></section>
<section id="what-happens-when-k-is-too-big" class="slide level2 smaller">
<h2>What happens when K is too big?</h2>
<div>
<ul>
<li class="fragment"><p>How many variables (max) can you use in a model?</p>
<ul>
<li class="fragment"><span class="math display">\[max \ k = rank(X'X)\]</span></li>
</ul></li>
<li class="fragment"><p>What happens when you add too many variables in a model?</p>
<ul>
<li class="fragment"><p>Increase Multicolinearity and coefficient variance (too much noise)</p></li>
<li class="fragment"><p>R2 overly large (without explaining much)</p></li>
<li class="fragment"><p>Far more difficult to interpret (too many factors)</p></li>
<li class="fragment"><p>May introduce endogeneity (when it wasnt a problem before)</p></li>
</ul></li>
<li class="fragment"><p>How can you solve the problem?</p>
<ul>
<li class="fragment">You select only a few of the variables, based on theory, and contribution to the model</li>
</ul></li>
<li class="fragment"><p>What if you can’t choose?</p></li>
</ul>
</div>
</section>
<section id="ml-we-let-the-choose-for-you" class="slide level2 smaller">
<h2>ML: We let the 💻Choose for you</h2>
<blockquote>
<p>Before we start. The methodology we will discuss are usually meant to get models with “good” predictive power, and some times better interpretability, not so much stat-inference (although its possible)</p>
</blockquote>
<p>When you do not know how to choose, you could try select a subset of variables from your model such that you maximize the predictive power of the model.</p>
<p>This should go beyond IN sample predictive power, but instead maximize Out of sample predictive power.</p>
<p>This is typically achieved using the following:</p>
<p><span class="math display">\[
AR^2 = 1-\frac{SSR}{SST}\frac{n-1}{n-k-1} \\
AIC = n^{-1}(SSR + 2k\hat\sigma^2) \\
BIC = n^{-1}(SSR + ln(n) k\hat\sigma^2)
\]</span></p>
<p>Or using a method known as cross-validation (Comparing predictive power using data not used for model estimation)</p>
<p>However, we can always try to estimate a model with all variables!</p>
</section>
<section id="ridge-and-lasso-and-elasticnet" class="slide level2 smaller">
<h2>Ridge and Lasso and ElasticNet</h2>
<ul>
<li>Recall that when using OLS to obtain <span class="math inline">\(\beta's\)</span>, we try to minimize the following:</li>
</ul>
<p><span class="math display">\[
SSR = \sum_i(y_i - X_i \beta)^2
\]</span></p>
<ul>
<li><p>This has the restrictions of mentioned before (<span class="math inline">\(k &lt; N\)</span>). In addition to letting coefficents vary “too much”</p></li>
<li><p>An alternative is to use <strong>Ridge</strong> regression, which instead Minimizes the following:</p></li>
</ul>
<p><span class="math display">\[
rSS = \sum_i(y_i - X_i \beta)^2+ \lambda \sum_{k=1}^K\beta_k^2
\]</span></p>
<ul>
<li>This essentially aims to find parameters that reduces SSR, but also “controls” for how large <span class="math inline">\(\beta's\)</span> can be, using a shrinkage penalty that depends on <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<!-- -->
<ul>
<li>If <span class="math inline">\(\lambda = 0\)</span> you get Standard OLS, and if <span class="math inline">\(\lambda \rightarrow \infty\)</span> , you get a situation where all betas (but the constant) are zero. For intermediate values, you may have better models than OLS, because you can balance Bias (when <span class="math inline">\(\beta's\)</span> are zero) with increase variance (when all <span class="math inline">\(\beta's\)</span> vary as they “please”)</li>
</ul>
</section>
<section id="section-7" class="slide level2 smaller">
<h2></h2>
<ul>
<li>We usually start with Ridge, because is relatively Easy to implement, since it has a close form Solution:</li>
</ul>
<p><span class="math display">\[
\beta = (X'X + \lambda I)^{-1}{X'y}
\]</span></p>
<div class="sourceCode" id="cb12" style="font-size: 120%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">sysuse</span> oaxaca, <span class="kw">clear</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="kw">keep</span> <span class="kw">if</span> lnwage!=.</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="kw">gen</span> male = 1-female</span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="kw">mata</span>:</span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="fu">y</span> = st_data(.,<span class="st">"lnwage"</span>)</span>
<span id="cb12-6"><a href="#cb12-6"></a>x = st_data(.,<span class="st">"educ exper female male"</span>),<span class="fu">J</span>(1434,1,1)</span>
<span id="cb12-7"><a href="#cb12-7"></a>i0 = <span class="fu">I</span>(5);i0[5,5]=0</span>
<span id="cb12-8"><a href="#cb12-8"></a>xx = (<span class="kw">cross</span>(x,x)) ; xy = (<span class="kw">cross</span>(x,<span class="fu">y</span>))</span>
<span id="cb12-9"><a href="#cb12-9"></a>bb0 = <span class="fu">invsym</span>(xx)*xy </span>
<span id="cb12-10"><a href="#cb12-10"></a>bb1 = <span class="fu">invsym</span>(xx:+i0*1)*xy </span>
<span id="cb12-11"><a href="#cb12-11"></a>bb10 = <span class="fu">invsym</span>(xx:+i0*10)*xy </span>
<span id="cb12-12"><a href="#cb12-12"></a>bb100 = <span class="fu">invsym</span>(xx:+i0*100)*xy </span>
<span id="cb12-13"><a href="#cb12-13"></a>bb1000 = <span class="fu">invsym</span>(xx:+i0*1000)*xy </span>
<span id="cb12-14"><a href="#cb12-14"></a>bb0,bb1,bb10,bb100,bb1000</span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="kw">end</span> </span>
<span id="cb12-16"><a href="#cb12-16"></a></span>
<span id="cb12-17"><a href="#cb12-17"></a>                1              2              3              4              5</span>
<span id="cb12-18"><a href="#cb12-18"></a>  +----------------------------------------------------------------------------+</span>
<span id="cb12-19"><a href="#cb12-19"></a>1 |   .0858251775    .0858183338    .0857563567    .0851046501    .0778292498  |</span>
<span id="cb12-20"><a href="#cb12-20"></a>2 |   .0147342796    .0147345813    .0147372042    .0147554544    .0146298058  |</span>
<span id="cb12-21"><a href="#cb12-21"></a>3 |  -.0949227416    -.047396817   -.0468240416    -.041806663   -.0208062854  |</span>
<span id="cb12-22"><a href="#cb12-22"></a>4 |             0     .047396817    .0468240416     .041806663    .0208062854  |</span>
<span id="cb12-23"><a href="#cb12-23"></a>5 |   2.218849962    2.171466638    2.172174327    2.179690914    2.266275433  |</span>
<span id="cb12-24"><a href="#cb12-24"></a>  +----------------------------------------------------------------------------+</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="lasso-and-elastic-net" class="slide level2 smaller">
<h2>Lasso and Elastic Net</h2>
<ul>
<li><p>Ridge is a relatively easy model to understand and estimate, since it has a close form solution. It has the slight disadvantage that you still estimate a coefficient for “every” variable (tho some are very small)</p></li>
<li><p>Another approach, that overcomes this advantage is known as Lasso.</p></li>
</ul>
<p><span class="math display">\[
LSS = \sum_i(y_i - X_i \beta)^2+ \lambda \sum_{k=1}^K |\beta_k|
\]</span></p>
<ul>
<li><p>and the one known as Elastic net</p>
<p><span class="math display">\[
eSS = \sum_i(y_i - X_i \beta)^2+ \lambda_L \sum_{k=1}^K |\beta_k| +
\lambda_r \sum_{k=1}^K \beta_k^2
\]</span></p></li>
<li><p>Lasso has the advantage of forcing some coefficients exactly to zero, when <span class="math inline">\(\lambda\)</span> is sufficiently large.</p></li>
<li><p>Elastic net tries to use the benefits from both approaches.</p></li>
</ul>
</section>
<section id="lasso-vs-ridge" class="slide level2">
<h2>Lasso vs Ridge</h2>

<img data-src="images/image-394882719.png" class="r-stretch"></section>
<section id="considerations" class="slide level2">
<h2>Considerations:</h2>
<p>As with many methodologies, the benefits from this approaches is not free.</p>
<ol type="1">
<li>You need to choose tuning parameters “wisely” using approaches such as AIC, BIC, or cross validation.</li>
<li>The model you get may improve prediction, but inference is not as straight forward.</li>
<li>It also requires working with Standardized coefficients. (so the same penalty can be used for all variables in the model.</li>
</ol>
<p>Nevertheless, they can be used as starting point for model selection.</p>
<p>if interested, look into <code>Stata</code> introduction to <code>Lasso</code> regression. <code>help Lasso intro</code></p>
</section>
<section id="brief-example" class="slide level2">
<h2>Brief Example:</h2>
<div class="sourceCode" id="cb13" style="font-size: 100%"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb13-1"><a href="#cb13-1"></a>frause oaxaca, <span class="kw">clear</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="kw">keep</span> <span class="kw">if</span> lnwage!=.</span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="kw">reg</span> lnwage i.age</span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="kw">predict</span> p_ols</span>
<span id="cb13-5"><a href="#cb13-5"></a>elasticnet linear lnwage i.age, selection(cv, alllambdas)  <span class="kw">alpha</span>(0)</span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="kw">predict</span> p_ridge</span>
<span id="cb13-7"><a href="#cb13-7"></a>lasso linear lnwage i.age, selection(cv, alllambdas)  </span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="kw">predict</span> p_lasso</span>
<span id="cb13-9"><a href="#cb13-9"></a>elasticnet linear lnwage i.age, selection(cv, alllambdas)   </span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="kw">predict</span> p_elastic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<img data-src="images/image-1604739776.png" class="r-stretch quarto-figure-center"></section>
<section id="shrinking-coefficients" class="slide level2">
<h2>Shrinking Coefficients</h2>

<img data-src="./figures/lasso_ridge.png" class="r-stretch quarto-figure-center"><p class="caption">Lasso vs Ridge</p></section></section>
<section id="next-non-semi-parametric-models" class="title-slide slide level1 center">
<h1>Next: Non &amp; Semi Parametric models</h1>
<div class="footer footer-default">

</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="OLS_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="OLS_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="OLS_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="OLS_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1200,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>